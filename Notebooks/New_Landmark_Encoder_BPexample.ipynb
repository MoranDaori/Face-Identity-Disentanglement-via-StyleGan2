{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Landmark_Encoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYuOZIlBgbY7"
      },
      "source": [
        "from torchvision.models import *\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q0MqhjZgbWA"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, dilation=1, padding='same'):\r\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "    if padding == 'same':\r\n",
        "        return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                         padding=1, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "class ResBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1,\r\n",
        "                 kernel_size=3,\r\n",
        "                 norm_layer=None):\r\n",
        "        super(ResBlock, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "\r\n",
        "        self.shortcut_conv = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride)\r\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes // 2, kernel_size=1, stride=1, padding=0)\r\n",
        "        self.conv2 = nn.Conv2d(planes // 2, planes // 2, kernel_size=kernel_size, stride=stride, padding=kernel_size // 2)\r\n",
        "        self.conv3 = nn.Conv2d(planes // 2, planes, kernel_size=1, stride=1, padding=0)\r\n",
        "\r\n",
        "        self.normalizer_fn = norm_layer(planes)\r\n",
        "        self.activation_fn = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "        self.stride = stride\r\n",
        "        self.out_planes = planes\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        shortcut = x\r\n",
        "        (_, _, _, x_planes) = x.size()\r\n",
        "\r\n",
        "        if self.stride != 1 or x_planes != self.out_planes:\r\n",
        "            shortcut = self.shortcut_conv(x)\r\n",
        "\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "\r\n",
        "        x += shortcut\r\n",
        "        x = self.normalizer_fn(x)\r\n",
        "        x = self.activation_fn(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dICSGtoagb3_"
      },
      "source": [
        "class ResFCN256(nn.Module):\r\n",
        "    def __init__(self, resolution_input=256, resolution_output=256, channel=3, size=16):\r\n",
        "        super().__init__()\r\n",
        "        self.input_resolution = resolution_input\r\n",
        "        self.output_resolution = resolution_output\r\n",
        "        self.channel = channel\r\n",
        "        self.size = size\r\n",
        "\r\n",
        "        # Encoder\r\n",
        "        self.block0 = conv3x3(in_planes=3, out_planes=self.size, padding='same')\r\n",
        "        self.block1 = ResBlock(inplanes=self.size, planes=self.size * 2, stride=2)\r\n",
        "        self.block2 = ResBlock(inplanes=self.size * 2, planes=self.size * 2, stride=1)\r\n",
        "        self.block3 = ResBlock(inplanes=self.size * 2, planes=self.size * 4, stride=2)\r\n",
        "        self.block4 = ResBlock(inplanes=self.size * 4, planes=self.size * 4, stride=1)\r\n",
        "        self.block5 = ResBlock(inplanes=self.size * 4, planes=self.size * 8, stride=2)\r\n",
        "        self.block6 = ResBlock(inplanes=self.size * 8, planes=self.size * 8, stride=1)\r\n",
        "        self.block7 = ResBlock(inplanes=self.size * 8, planes=self.size * 16, stride=2)\r\n",
        "        self.block8 = ResBlock(inplanes=self.size * 16, planes=self.size * 16, stride=1)\r\n",
        "        self.block9 = ResBlock(inplanes=self.size * 16, planes=self.size * 32, stride=2)\r\n",
        "        self.block10 = ResBlock(inplanes=self.size * 32, planes=self.size * 32, stride=1)\r\n",
        "\r\n",
        "        # Decoder\r\n",
        "        self.upsample0 = nn.ConvTranspose2d(self.size * 32, self.size * 32, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "        self.upsample1 = nn.ConvTranspose2d(self.size * 32, self.size * 16, kernel_size=4, stride=2,\r\n",
        "                                            padding=1)  # half downsample.\r\n",
        "        self.upsample2 = nn.ConvTranspose2d(self.size * 16, self.size * 16, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "        self.upsample3 = nn.ConvTranspose2d(self.size * 16, self.size * 16, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        self.upsample4 = nn.ConvTranspose2d(self.size * 16, self.size * 8, kernel_size=4, stride=2,\r\n",
        "                                            padding=1)  # half downsample.\r\n",
        "        self.upsample5 = nn.ConvTranspose2d(self.size * 8, self.size * 8, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "        self.upsample6 = nn.ConvTranspose2d(self.size * 8, self.size * 8, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        self.upsample7 = nn.ConvTranspose2d(self.size * 8, self.size * 4, kernel_size=4, stride=2,\r\n",
        "                                            padding=1)  # half downsample.\r\n",
        "        self.upsample8 = nn.ConvTranspose2d(self.size * 4, self.size * 4, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "        self.upsample9 = nn.ConvTranspose2d(self.size * 4, self.size * 4, kernel_size=3, stride=1,\r\n",
        "                                            padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        self.upsample10 = nn.ConvTranspose2d(self.size * 4, self.size * 2, kernel_size=4, stride=2,\r\n",
        "                                             padding=1)  # half downsample.\r\n",
        "        self.upsample11 = nn.ConvTranspose2d(self.size * 2, self.size * 2, kernel_size=3, stride=1,\r\n",
        "                                             padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        self.upsample12 = nn.ConvTranspose2d(self.size * 2, self.size, kernel_size=4, stride=2,\r\n",
        "                                             padding=1)  # half downsample.\r\n",
        "        self.upsample13 = nn.ConvTranspose2d(self.size, self.size, kernel_size=3, stride=1,\r\n",
        "                                             padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        self.upsample14 = nn.ConvTranspose2d(self.size, self.channel, kernel_size=3, stride=1,\r\n",
        "                                             padding=1)  # keep shape invariant.\r\n",
        "        self.upsample15 = nn.ConvTranspose2d(self.channel, self.channel, kernel_size=3, stride=1,\r\n",
        "                                             padding=1)  # keep shape invariant.\r\n",
        "        self.upsample16 = nn.ConvTranspose2d(self.channel, self.channel, kernel_size=3, stride=1,\r\n",
        "                                             padding=1)  # keep shape invariant.\r\n",
        "\r\n",
        "        # ACT\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        se = self.block0(x)  # 256 x 256 x 16\r\n",
        "        se = self.block1(se)  # 128 x 128 x 32\r\n",
        "        se = self.block2(se)  # 128 x 128 x 32\r\n",
        "        se = self.block3(se)  # 64 x 64 x 64\r\n",
        "        se = self.block4(se)  # 64 x 64 x 64\r\n",
        "        se = self.block5(se)  # 32 x 32 x 128\r\n",
        "        se = self.block6(se)  # 32 x 32 x 128\r\n",
        "        se = self.block7(se)  # 16 x 16 x 256\r\n",
        "        se = self.block8(se)  # 16 x 16 x 256\r\n",
        "        se = self.block9(se)  # 8 x 8 x 512\r\n",
        "        se = self.block10(se)  # 8 x 8 x 512\r\n",
        "\r\n",
        "        pd = self.upsample0(se)  # 8 x 8 x 512\r\n",
        "        pd = self.upsample1(pd)  # 16 x 16 x 256\r\n",
        "        pd = self.upsample2(pd)  # 16 x 16 x 256\r\n",
        "        pd = self.upsample3(pd)  # 16 x 16 x 256\r\n",
        "        pd = self.upsample4(pd)  # 32 x 32 x 128\r\n",
        "        pd = self.upsample5(pd)  # 32 x 32 x 128\r\n",
        "        pd = self.upsample6(pd)  # 32 x 32 x 128\r\n",
        "        pd = self.upsample7(pd)  # 64 x 64 x 64\r\n",
        "        pd = self.upsample8(pd)  # 64 x 64 x 64\r\n",
        "        pd = self.upsample9(pd)  # 64 x 64 x 64\r\n",
        "\r\n",
        "        pd = self.upsample10(pd)  # 128 x 128 x 32\r\n",
        "        pd = self.upsample11(pd)  # 128 x 128 x 32\r\n",
        "        pd = self.upsample12(pd)  # 256 x 256 x 16\r\n",
        "        pd = self.upsample13(pd)  # 256 x 256 x 16\r\n",
        "        pd = self.upsample14(pd)  # 256 x 256 x 3\r\n",
        "        pd = self.upsample15(pd)  # 256 x 256 x 3\r\n",
        "        pos = self.upsample16(pd)  # 256 x 256 x 3\r\n",
        "\r\n",
        "        pos = self.sigmoid(pos)\r\n",
        "        return pos"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ12n3-CzC0H"
      },
      "source": [
        "class Encoder_Landmarks(nn.Module):\r\n",
        "    def __init__(self, model_dir):\r\n",
        "      super(Encoder_Landmarks, self).__init__()\r\n",
        "      self.model = ResFCN256()\r\n",
        "      state = torch.load(model_dir)\r\n",
        "      self.model.load_state_dict(state['prnet'])\r\n",
        "      # self.model.eval()  # ?\r\n",
        "      # if torch.cuda.device_count() > 0:\r\n",
        "      #     self.model = self.model.to(\"cuda\")\r\n",
        "    \r\n",
        "    def forward(self, data):\r\n",
        "      return self.model(data)\r\n",
        "\r\n",
        "    def backprop(self, input_image, output_image):\r\n",
        "      # model = self.model.train() # ?\r\n",
        "\r\n",
        "      if torch.cuda.device_count() > 0:\r\n",
        "        self.model = self.model.to(\"cuda\")\r\n",
        "        input_image = input_image.to(\"cuda\")\r\n",
        "        output_image = output_image.to(\"cuda\")\r\n",
        "\r\n",
        "      optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001, betas=(0.5, 0.999))\r\n",
        "      optimizer.zero_grad()\r\n",
        "        \r\n",
        "      input_attr_lnd = self.model(input_image)\r\n",
        "      output_lnd = self.model(output_image)\r\n",
        "\r\n",
        "      loss = torch.norm(input_attr_lnd - output_lnd , p=2)\r\n",
        "      print(loss)\r\n",
        "\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3hdc2qQ2ctf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQgVvZ4mmYgb"
      },
      "source": [
        "def get_data(DATA_DIR, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], image_size = 256):\r\n",
        "    full_dataset = dset.ImageFolder(root=DATA_DIR,\r\n",
        "                           transform=transforms.Compose([\r\n",
        "                                      transforms.Resize(image_size),\r\n",
        "                                      # transforms.CenterCrop(image_size),\r\n",
        "                                      transforms.ToTensor(),\r\n",
        "                                      transforms.Normalize(mean=mean, std=std),\r\n",
        "                                  ]))\r\n",
        "    return full_dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6_XyaM52Qlv"
      },
      "source": [
        "def make_loaders(dataset, batch_size):\r\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=dataset,\r\n",
        "                                              batch_size=batch_size)\r\n",
        "\r\n",
        "    return test_loader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwf2sDQF88rR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlFkcvSy88gz"
      },
      "source": [
        "# data_loader example "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJlIOa2RzyUZ"
      },
      "source": [
        "def net_forward_loader(prn, data_loader):\r\n",
        "    if torch.cuda.device_count() > 0:\r\n",
        "      model = prn.model.to(\"cuda\")\r\n",
        "    with torch.no_grad():\r\n",
        "        image, _ = next(iter(data_loader))\r\n",
        "        if torch.cuda.device_count() > 0:\r\n",
        "            image = image.to(\"cuda\")\r\n",
        "        output = model(image)\r\n",
        "    return output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp2OyC0BxoiP"
      },
      "source": [
        "model_dir = r'/content/drive/MyDrive/Colab Notebooks/workshop/Weights/latest.pth'\r\n",
        "DATA_DIR = r'/content/drive/MyDrive/Colab Notebooks/workshop/Datasets/real_small/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YRECL5t1nbW"
      },
      "source": [
        "prn = Encoder_Landmarks(model_dir)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US304M2zmYUL"
      },
      "source": [
        "batch_size = 8\r\n",
        "data_folder = get_data(DATA_DIR)\r\n",
        "data_loader = make_loaders(data_folder, batch_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfUe9TDmqtM"
      },
      "source": [
        "output = net_forward_loader(prn, data_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1TjEEPRmqqt",
        "outputId": "8f077441-25a8-4d70-e3f7-473678be3915"
      },
      "source": [
        "print(output.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RPTRMoVnCaA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHbRKPN99RQi"
      },
      "source": [
        "# backprop example , preper images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y-CSvyGD8Va"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7qpOUXeDilS"
      },
      "source": [
        "def image_transform(image_path, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], image_size = 256):\r\n",
        "  transform_img = transforms.Compose([\r\n",
        "    transforms.Resize(image_size),\r\n",
        "    # transforms.CenterCrop(image_size),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=mean, std=std),\r\n",
        "  ])\r\n",
        "  image = Image.open(image_path)\r\n",
        "  image_t = transform_img(image)\r\n",
        "  image_t = image_t.unsqueeze(0)\r\n",
        "  return image_t"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nUd9IXoEo76"
      },
      "source": [
        "input_path = DATA_DIR + \"01000/01011.png\"\r\n",
        "input_attr_lnd = image_transform(input_path)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857RNuZr4qmQ"
      },
      "source": [
        "output_path = DATA_DIR + \"01000/01012.png\"\r\n",
        "output_lnd = image_transform(output_path)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEFZspp4XgK",
        "outputId": "abc29488-23d9-43fe-80af-2917630c3eaa"
      },
      "source": [
        "prn.backprop(input_attr_lnd, output_lnd)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(30.4699, device='cuda:0', grad_fn=<NormBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OnuDxo14Xdu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}